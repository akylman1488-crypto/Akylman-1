import json
import os
from groq import Groq
from config import GROQ_API_KEY, PROMPTS
import groq
import random

# –°–ø–∏—Å–æ–∫ —Ç–≤–æ–∏—Ö –∫–ª—é—á–µ–π (–¥–æ–±–∞–≤—å —Å—é–¥–∞ —Å—Ç–æ–ª—å–∫–æ, —Å–∫–æ–ª—å–∫–æ –µ—Å—Ç—å)
GROQ_KEYS = [
    "",
    "gsk_key_2_–≤–∞—à–∞_—Å—Ç—Ä–æ–∫–∞",
    "gsk_key_3_–≤–∞—à–∞_—Å—Ç—Ä–æ–∫–∞"
]

def get_ai_response(prompt):
    # –ö–æ–ø–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–π, —á—Ç–æ–±—ã –ø—Ä–æ–±–æ–≤–∞—Ç—å –∏—Ö –ø–æ –æ—á–µ—Ä–µ–¥–∏
    available_keys = GROQ_KEYS.copy()
    
    while available_keys:
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∫–ª—é—á –∏–∑ —Å–ø–∏—Å–∫–∞
        current_key = available_keys[0]
        
        try:
            client = groq.Client(api_key=current_key)
            response = client.chat.completions.create(
                model="llama3-8b-8192",
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content
            
        except Exception as e:
            # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ 429 (–ª–∏–º–∏—Ç –∏—Å—á–µ—Ä–ø–∞–Ω)
            if "429" in str(e) or "rate_limit" in str(e).lower():
                print(f"–ö–ª—é—á {current_key[:10]}... –∏—Å—á–µ—Ä–ø–∞–Ω. –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å.")
                available_keys.pop(0) # –£–¥–∞–ª—è–µ–º –Ω–µ—Ä–∞–±–æ—á–∏–π –∫–ª—é—á –∏ –∏–¥–µ–º –Ω–∞ –≤—Ç–æ—Ä–æ–π –∫—Ä—É–≥
            else:
                return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}"
    
    return "–ò–∑–≤–∏–Ω–∏, –≤—Å–µ –ª–∏–º–∏—Ç—ã –Ω–∞ —Å–µ–≥–æ–¥–Ω—è –∏—Å—á–µ—Ä–ø–∞–Ω—ã –¥–∞–∂–µ –Ω–∞ –∑–∞–ø–∞—Å–Ω—ã—Ö –∫–ª—é—á–∞—Ö!"

def get_ai_response(prompt, subject="General", context=""):
    p_lower = prompt.lower()
    who_list = ["–∫—Ç–æ —Ç–µ–±—è —Å–æ–∑–¥–∞–ª", "–∫—Ç–æ —Ç–≤–æ–π —Å–æ–∑–¥–∞—Ç–µ–ª—å", "—á–µ–π —Ç—ã –ø—Ä–æ–µ–∫—Ç", "–∫—Ç–æ —Ç–≤–æ–π –∞–≤—Ç–æ—Ä"]
    
    if any(q in p_lower for q in who_list):
        return "–ú–µ–Ω—è —Å–æ–∑–¥–∞–ª –ò—Å–∞–Ω—É—Ä! üòé –Ø ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –ò–ò-–ø—Ä–æ–µ–∫—Ç, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∏–º –ª–∏—á–Ω–æ."

client = Groq(api_key=GROQ_API_KEY)

def get_quiz_json(topic, subject):
    prompt = f"""
    –°–æ–∑–¥–∞–π —Ç–µ—Å—Ç –Ω–∞ —Ç–µ–º—É '{topic}' –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É '{subject}'.
    –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON —Ñ–æ—Ä–º–∞—Ç (—Å–ø–∏—Å–æ–∫ –∏–∑ 3 –æ–±—ä–µ–∫—Ç–æ–≤).
    –ö–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç: {{"question": "—Ç–µ–∫—Å—Ç", "options": ["–ê", "–ë", "–í", "–ì"], "answer": "–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç"}}
    –ù–∏–∫–∞–∫–æ–≥–æ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞, —Ç–æ–ª—å–∫–æ —á–∏—Å—Ç—ã–π JSON.
    """
    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[{"role": "user", "content": prompt}],
            response_format={ "type": "json_object" }
        )
        data = json.loads(completion.choices[0].message.content)
        return data.get("questions", data) if isinstance(data, dict) else data
    except:
        return None

def get_ai_response(prompt, subject, history=None, context=""):
    if history is None: history = []
        
    system_msg = PROMPTS.get(subject, PROMPTS.get("General", "You are Akylman"))
    
    messages = [{"role": "system", "content": f"{system_msg}\nContext: {context}"}]
    
    for msg in history[-5:]:
        messages.append({"role": msg["role"], "content": msg["content"]})
    
    messages.append({"role": "user", "content": prompt})
    
    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.6
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {e}"

