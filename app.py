import streamlit as st
from groq import Groq
from duckduckgo_search import DDGS
from datetime import datetime
from pypdf import PdfReader

st.set_page_config(page_title="Akylman AI: Online", page_icon="üåê")

if "GROQ_API_KEY" in st.secrets:
    client = Groq(api_key=st.secrets["GROQ_API_KEY"])
else:
    st.error("–ù–µ—Ç –∫–ª—é—á–∞ API –≤ —Å–µ–∫—Ä–µ—Ç–∞—Ö!")

if "messages" not in st.session_state:
    st.session_state.messages = []
if "memory" not in st.session_state:
    st.session_state.memory = "–¢—ã ‚Äî Akylman, –º—É–¥—Ä—ã–π AI. –¢—ã –ø–æ–º–æ–≥–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é."

def search_web(query):
    """–ò—â–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ DuckDuckGo"""
    try:
        results = DDGS().text(query, max_results=3)
        if results:
            context = "\n".join([f"- {r['title']}: {r['body']}" for r in results])
            return context
        return "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}"

def generate_response(messages, model, web_enabled, context_file=""):
    system_prompt = st.session_state.memory

    if context_file:
        system_prompt += f"\n\n[–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –§–ê–ô–õ–ê]:\n{context_file}"

    last_user_msg = messages[-1]["content"]
    if web_enabled:
        with st.spinner("üîç –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ..."):
            web_results = search_web(last_user_msg)
        system_prompt += f"\n\n[–î–ê–ù–ù–´–ï –ò–ó –ò–ù–¢–ï–†–ù–ï–¢–ê –ü–û –ó–ê–ü–†–û–°–£ '{last_user_msg}']:\n{web_results}\n–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, –µ—Å–ª–∏ –æ–Ω–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã."

    all_messages = [{"role": "system", "content": system_prompt}]
    for m in messages:
        all_messages.append({"role": m["role"], "content": m["content"]})

    try:
        chat_completion = client.chat.completions.create(
            messages=all_messages,
            model=model,
            temperature=0.6,
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {str(e)}"

with st.sidebar:
    st.title("üåê Akylman 4.0")

    model = st.selectbox(
        "–ú–æ–∑–≥:",
        ("llama-3.3-70b-versatile", "llama-3.1-8b-instant", "mixtral-8x7b-32768")
    )

    st.markdown("---")

    col1, col2 = st.columns(2)
    with col1:
        web_search = st.toggle("üåê –ò–Ω—Ç–µ—Ä–Ω–µ—Ç", value=False)
    with col2:
        if st.button("üóëÔ∏è –°–±—Ä–æ—Å"):
            st.session_state.messages = []
            st.rerun()

    st.markdown("---")

    with st.expander("üß† –û–±—É—á–µ–Ω–∏–µ –∏ –ü–∞–º—è—Ç—å"):
        new_memory = st.text_area(
            "–ß–µ–º—É –Ω–∞—É—á–∏—Ç—å –ê–∫—ã–ª–º–∞–Ω–∞?", 
            value=st.session_state.memory,
            height=150,
            help="–ù–∞–ø–∏—à–∏ —Å—é–¥–∞ –ø—Ä–∞–≤–∏–ª–∞, –∫–æ—Ç–æ—Ä—ã–µ –±–æ—Ç –¥–æ–ª–∂–µ–Ω –ø–æ–º–Ω–∏—Ç—å –≤—Å–µ–≥–¥–∞."
        )
        if new_memory != st.session_state.memory:
            st.session_state.memory = new_memory
            st.success("–û–±–Ω–æ–≤–ª–µ–Ω–æ!")

    uploaded_file = st.file_uploader("üìÇ –î–æ–∫—É–º–µ–Ω—Ç—ã", type=["pdf", "txt"])

st.title("Akylman AI")

if not st.session_state.messages:
    hour = datetime.now().hour
    greeting = "–ü—Ä–∏–≤–µ—Ç! –Ø –Ω–∞ —Å–≤—è–∑–∏. –í–∫–ª—é—á–∏ '–ò–Ω—Ç–µ—Ä–Ω–µ—Ç' —Å–ª–µ–≤–∞, –µ—Å–ª–∏ –Ω—É–∂–Ω—ã —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ."
    st.session_state.messages.append({"role": "assistant", "content": greeting})

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("–°–ø—Ä–æ—Å–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å..."):
    file_text = ""
    if uploaded_file:
        try:
            if uploaded_file.type == "application/pdf":
                reader = PdfReader(uploaded_file)
                file_text = " ".join([p.extract_text() for p in reader.pages if p.extract_text()])
            else:
                file_text = uploaded_file.read().decode("utf-8")
        except:
            st.error("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞")

    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response = generate_response(st.session_state.messages, model, web_search, file_text)
        st.markdown(response)
    
    st.session_state.messages.append({"role": "assistant", "content": response})
