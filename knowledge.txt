import os
from groq import Groq
from config import GROQ_API_KEY, PROMPTS

client = Groq(api_key=GROQ_API_KEY)

def load_permanent_memory():
    if os.path.exists("knowledge.txt"):
        with open("knowledge.txt", "r", encoding="utf-8") as f:
            return f.read()
    return ""

def get_ai_response(prompt, subject, history=None, context=""):
    if history is None: history = []
    
    memory = load_permanent_memory()
    system_msg = PROMPTS.get(subject, PROMPTS.get("General", "You are Akylman"))
    
    full_context = f"Твои постоянные знания: {memory}\nКонтекст текущего файла: {context}"
    
    messages = [{"role": "system", "content": f"{system_msg}\n{full_context}"}]
    for msg in history[-5:]:
        messages.append({"role": msg["role"], "content": msg["content"]})
    messages.append({"role": "user", "content": prompt})
    
    try:
        completion = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            temperature=0.6
        )
        return completion.choices[0].message.content
    except:
        return "⚠️ Ошибка."
